{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine monthly taxi trip datasets to keep essential information & merge with taxi IDs dataset to add latitude/longitude in place of IDs.\n",
    "Process all months (2012)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_ids = pd.read_csv('refined_taxi_ids.csv')\n",
    "for month in range(1, 13):  \n",
    "    month_str = f\"{month:02}\"  \n",
    "    file_path = f'new_york/new_york_taxi_trips_2012/yellow_tripdata_2012-{month_str}.parquet'\n",
    "    output_file_path = f'refined_taxi_data_2012_{month_str}.parquet'\n",
    "\n",
    "    taxi_trips = pd.read_parquet(file_path)\n",
    "    \n",
    "    taxi_trips = taxi_trips.drop(columns=['VendorID', 'passenger_count', 'RatecodeID',\n",
    "                                          'store_and_fwd_flag', 'payment_type', 'fare_amount',\n",
    "                                          'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
    "                                          'improvement_surcharge', 'total_amount',\n",
    "                                          'congestion_surcharge', 'airport_fee'])\n",
    "\n",
    "    # Merge for Pickup Locations\n",
    "    trips_with_lat_long = pd.merge(taxi_trips, taxi_ids[['PULocationID', 'PU_lat', 'PU_long']],\n",
    "                                   how='left', left_on='PULocationID', right_on='PULocationID')\n",
    "\n",
    "    # Merge for Dropoff Locations\n",
    "    trips_with_lat_long = pd.merge(trips_with_lat_long, taxi_ids[['DOLocationID', 'DO_lat', 'DO_long']],\n",
    "                                   how='left', left_on='DOLocationID', right_on='DOLocationID')\n",
    "\n",
    "    trips_with_lat_long.rename(columns={'tpep_pickup_datetime': 'PU_datetime'}, inplace=True)\n",
    "    trips_with_lat_long.rename(columns={'tpep_dropoff_datetime': 'DO_datetime'}, inplace=True)\n",
    "    trips_with_lat_long = trips_with_lat_long.drop(columns=['PULocationID', 'DOLocationID'])\n",
    "\n",
    "    trips_with_lat_long.to_parquet(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a single annual dataset from the monthly datasets to merge with final dataset.\n",
    "Interim (monthly) files deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [f'refined_taxi_data_2012_{month:02}.csv' for month in range(1, 13)]\n",
    "taxi_trips_2012 = dd.read_csv(csv_files)\n",
    "taxi_trips_2012.to_parquet('refined_taxi_data_year_2012.parquet', write_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process all months for 2013 (Used parquet files this time to save space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_ids = pd.read_csv('refined_taxi_ids.csv')\n",
    "for month in range(1, 13):  \n",
    "    month_str = f\"{month:02}\"  \n",
    "    file_path = f'new_york/new_york_taxi_trips_2013/yellow_tripdata_2013-{month_str}.parquet'\n",
    "    output_file_path = f'refined_taxi_data_2013_{month_str}.parquet'\n",
    "\n",
    "    taxi_trips = pd.read_parquet(file_path)\n",
    "    \n",
    "    taxi_trips = taxi_trips.drop(columns=['VendorID', 'passenger_count', 'RatecodeID',\n",
    "                                          'store_and_fwd_flag', 'payment_type', 'fare_amount',\n",
    "                                          'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
    "                                          'improvement_surcharge', 'total_amount',\n",
    "                                          'congestion_surcharge', 'airport_fee'])\n",
    "\n",
    "    # Merge for Pickup Locations\n",
    "    trips_with_lat_long = pd.merge(taxi_trips, taxi_ids[['PULocationID', 'PU_lat', 'PU_long']],\n",
    "                                   how='left', left_on='PULocationID', right_on='PULocationID')\n",
    "\n",
    "    # Merge for Dropoff Locations\n",
    "    trips_with_lat_long = pd.merge(trips_with_lat_long, taxi_ids[['DOLocationID', 'DO_lat', 'DO_long']],\n",
    "                                   how='left', left_on='DOLocationID', right_on='DOLocationID')\n",
    "\n",
    "    trips_with_lat_long.rename(columns={'tpep_pickup_datetime': 'PU_datetime'}, inplace=True)\n",
    "    trips_with_lat_long.rename(columns={'tpep_dropoff_datetime': 'DO_datetime'}, inplace=True)\n",
    "    trips_with_lat_long = trips_with_lat_long.drop(columns=['PULocationID', 'DOLocationID'])\n",
    "\n",
    "    trips_with_lat_long.to_parquet(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a single annual dataset from the monthly datasets to merge with final dataset.\n",
    "Interim (monthly) files deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = [f'refined_taxi_data_2013_{month:02}.parquet' for month in range (1,13)]\n",
    "taxi_trips_2013 = dd.read_parquet(parquet_files)\n",
    "taxi_trips_2013.to_parquet('refined_taxi_data_year_2013.parquet', write_index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
